{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import time,sys,statistics,csv\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sizes are  Train: 27000 , Validation: 3000 , Test: 7000\n"
     ]
    }
   ],
   "source": [
    "## The possible attributes in the data with the prediction at index 0. Smaller names for brevity.\n",
    "attributes = [\"rich\",\"age\",\"wc\",\"fnlwgt\",\"edu\",\"edun\",\"mar\",\"occ\",\"rel\",\"race\",\"sex\",\"capg\",\"canpl\",\"hpw\",\"nc\"]\n",
    "\n",
    "## Get the encoding of the csv file by replacing each categorical attribute value by its index.\n",
    "wc_l = \"Private, Self-emp-not-inc, Self-emp-inc, Federal-gov, Local-gov, State-gov, Without-pay, Never-worked\".split(\", \")\n",
    "edu_l = \"Bachelors, Some-college, 11th, HS-grad, Prof-school, Assoc-acdm, Assoc-voc, 9th, 7th-8th, 12th, Masters, 1st-4th, 10th, Doctorate, 5th-6th, Preschool\".split(\", \")\n",
    "mar_l = \"Married-civ-spouse, Divorced, Never-married, Separated, Widowed, Married-spouse-absent, Married-AF-spouse\".split(\", \")\n",
    "occ_l = \"Tech-support, Craft-repair, Other-service, Sales, Exec-managerial, Prof-specialty, Handlers-cleaners, Machine-op-inspct, Adm-clerical, Farming-fishing, Transport-moving, Priv-house-serv, Protective-serv, Armed-Forces\".split(\", \")\n",
    "rel_l = \"Wife, Own-child, Husband, Not-in-family, Other-relative, Unmarried\".split(\", \")\n",
    "race_l = \"White, Asian-Pac-Islander, Amer-Indian-Eskimo, Other, Black\".split(\", \")\n",
    "sex_l = \"Female, Male\".split(\", \")\n",
    "nc_l = \"United-States, Cambodia, England, Puerto-Rico, Canada, Germany, Outlying-US(Guam-USVI-etc), India, Japan, Greece, South, China, Cuba, Iran, Honduras, Philippines, Italy, Poland, Jamaica, Vietnam, Mexico, Portugal, Ireland, France, Dominican-Republic, Laos, Ecuador, Taiwan, Haiti, Columbia, Hungary, Guatemala, Nicaragua, Scotland, Thailand, Yugoslavia, El-Salvador, Trinadad&Tobago, Peru, Hong, Holand-Netherlands\".split(\", \")\n",
    "encode = {\n",
    "    \"rich\"   : {\"0\":0,\"1\":1},\n",
    "    \"wc\"     : {wc_l[i]:i for i in range(len(wc_l))},\n",
    "    \"edu\"    : {edu_l[i]:i for i in range(len(edu_l))},\n",
    "    \"mar\"    : {mar_l[i]:i for i in range(len(mar_l))},\n",
    "    \"occ\"    : {occ_l[i]:i for i in range(len(occ_l))},\n",
    "    \"rel\"    : {rel_l[i]:i for i in range(len(rel_l))},\n",
    "    \"race\"   : {race_l[i]:i for i in range(len(race_l))},\n",
    "    \"sex\"    : {sex_l[i]:i for i in range(len(sex_l))},\n",
    "    \"nc\"     : {nc_l[i]:i for i in range(len(nc_l))},\n",
    "    }\n",
    "\n",
    "attr_len = [2, 2, len(wc_l), 2, len(edu_l), 2, len(mar_l), len(occ_l), len(rel_l), len(race_l), len(sex_l), 2, 2, 2, len(nc_l)]\n",
    "\n",
    "def medians(file):\n",
    "    \"\"\"\n",
    "    Given a csv file, find the medians of the categorical attributes for the whole data.\n",
    "    params(1): \n",
    "        file : string : the name of the file\n",
    "    outputs(6):\n",
    "        median values for the categorical columns\n",
    "    \"\"\"\n",
    "    fin = open(file,\"r\")\n",
    "    reader = csv.reader(fin)\n",
    "    age, fnlwgt, edun, capg, capl, hpw = ([] for i in range(6))\n",
    "    total = 0\n",
    "    for row in reader:\n",
    "        total+=1\n",
    "        if(total==1):\n",
    "            continue\n",
    "        l = [x.lstrip().rstrip() for x in row]\n",
    "        age.append(int(l[0]));\n",
    "        fnlwgt.append(int(l[2]));\n",
    "        edun.append(int(l[4]));\n",
    "        capg.append(int(l[10]));\n",
    "        capl.append(int(l[11]));\n",
    "        hpw.append(int(l[12]));\n",
    "    fin.close()\n",
    "    return(statistics.median(age),statistics.median(fnlwgt),statistics.median(edun),statistics.median(capg),statistics.median(capl),statistics.median(hpw))\n",
    "\n",
    "def preprocess(file, median):\n",
    "    \"\"\"\n",
    "    Given a file, read its data by encoding categorical attributes and binarising continuos attributes based on median.\n",
    "    params(1): \n",
    "        file : string : the name of the file\n",
    "    outputs(6):\n",
    "        2D numpy array with the data\n",
    "    \"\"\"\n",
    "    # Calculate the medians\n",
    "    agem,fnlwgtm,edunm,capgm,caplm,hpwm = medians(file)\n",
    "    fin = open(file,\"r\")\n",
    "    reader = csv.reader(fin)\n",
    "    data = []\n",
    "    total = 0\n",
    "    for row in reader:\n",
    "        total+=1\n",
    "        # Skip line 0 in the file\n",
    "        if(total==1):\n",
    "            continue\n",
    "        l = [x.lstrip().rstrip() for x in row]\n",
    "        t = [0 for i in range(15)]\n",
    "        \n",
    "        # Encode the categorical attributes\n",
    "        t[0] = encode[\"rich\"][l[-1]]; t[2] = encode[\"wc\"][l[1]]; t[4] = encode[\"edu\"][l[3]]\n",
    "        t[6] = encode[\"mar\"][l[5]]; t[7] = encode[\"occ\"][l[6]]; t[8] = encode[\"rel\"][l[7]]\n",
    "        t[9] = encode[\"race\"][l[8]]; t[10] = encode[\"sex\"][l[9]]; t[14] = encode[\"nc\"][l[13]]\n",
    "        \n",
    "        # Binarize the numerical attributes based on median.\n",
    "        # Modify this section to read the file in part c where you split the continuos attributes baed on dynamic median values.\n",
    "        if(median):\n",
    "            t[1] = float(l[0])>=agem; t[3] = float(l[2])>=fnlwgtm; t[5] = float(l[4])>=edunm;\n",
    "            t[11] = float(l[10])>=capgm; t[12] = float(l[11])>=caplm; t[13] = float(l[12])>=hpwm;\n",
    "        else:\n",
    "            t[1] = l[0]; t[3] = l[2]; t[5] = l[4];\n",
    "            t[11] = l[10]; t[12] = l[11]; t[13] = l[12];\n",
    "        \n",
    "        # Convert some of the booleans to ints\n",
    "        data.append([int(x) for x in t])\n",
    "    \n",
    "    return np.array(data,dtype=np.int64)\n",
    "\n",
    "\n",
    "## Read the data\n",
    "train_data = preprocess(\"dtree_data/train.csv\", False)\n",
    "valid_data = preprocess(\"dtree_data/valid.csv\", False)\n",
    "test_data = preprocess(\"dtree_data/test.csv\", False)\n",
    "\n",
    "print(\"The sizes are \",\"Train:\",len(train_data),\", Validation:\",len(valid_data),\", Test:\",len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_median(ind):\n",
    "    if(ind==1 or ind==3 or ind==5 or ind==11 or ind==12 or ind==13):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def predict(inp_pt, dtree_ind):\n",
    "    global dtree\n",
    "    attr_ind = dtree[dtree_ind][0]\n",
    "    if(dtree[dtree_ind][1][inp_pt[attr_ind]]==-1):\n",
    "        return 1\n",
    "    elif(dtree[dtree_ind][1][inp_pt[attr_ind]]==-2):\n",
    "        return 0\n",
    "    else:\n",
    "        return predict(inp_pt, dtree[dtree_ind][1][inp_pt[attr_ind]])\n",
    "\n",
    "def get_acc(test_data):\n",
    "    corr = 0\n",
    "    total = 0\n",
    "    for data_pt in test_data:\n",
    "        my_pred = predict(data_pt, 1)\n",
    "        if(my_pred==data_pt[0]):\n",
    "            corr += 1\n",
    "        total += 1\n",
    "\n",
    "    return (corr+0.0)/total\n",
    "\n",
    "def calc_gain(new_inp, attr_ind):\n",
    "    rich = [0 for i in range(attr_len[attr_ind])]\n",
    "    poor = [0 for i in range(attr_len[attr_ind])]\n",
    "    num = 0\n",
    "    den = 0\n",
    "    med_arr = []\n",
    "    inp = copy.deepcopy(new_inp)\n",
    "    median = 0.0\n",
    "    if(is_median(attr_ind)):\n",
    "        for data_pt in inp:\n",
    "            med_arr.append(int(data_pt[attr_ind]))\n",
    "        median = statistics.median(med_arr)\n",
    "        new_data = []\n",
    "        for data_pt in inp:\n",
    "            new_data.append(int(float(data_pt[attr_ind])>=median))\n",
    "        for data_pt, new_dp in zip(inp, new_data):\n",
    "            data_pt[attr_ind] = new_dp\n",
    "    for data_pt in inp:\n",
    "        if(data_pt[0]==0):\n",
    "            poor[data_pt[attr_ind]] += 1\n",
    "        else:\n",
    "            rich[data_pt[attr_ind]] += 1\n",
    "    for i in range(attr_len[attr_ind]):\n",
    "        if(rich[i]!=0 and poor[i]!=0):\n",
    "            p_x = (rich[i] + 0.0)/(rich[i] + poor[i])\n",
    "            num += (rich[i] + poor[i])*(p_x*math.log(p_x) + (1-p_x)*math.log(1-p_x))\n",
    "            den += (rich[i] + poor[i])\n",
    "    if(den==0):\n",
    "        return 0, rich, poor, median\n",
    "    else:\n",
    "        return (num/den), rich, poor, median\n",
    "\n",
    "def max_gain(new_inp):\n",
    "    max_gn = float('-inf')\n",
    "    max_ind = -1\n",
    "    max_rich = []\n",
    "    max_poor = []\n",
    "    max_med = 0.0\n",
    "    rich = 0\n",
    "    poor = 0\n",
    "    inp = copy.deepcopy(new_inp)\n",
    "    for i in range(len(inp)):\n",
    "        if(inp[i][0]==0):\n",
    "            poor += 1\n",
    "        else:\n",
    "            rich += 1\n",
    "    if(rich==0 or poor==0):\n",
    "        return 0.0, max_ind, max_rich, max_poor, max_med\n",
    "    p_x = (rich + 0.0)/(rich + poor)\n",
    "    entropy = p_x*math.log(p_x) + (1-p_x)*math.log(1-p_x)\n",
    "    for attr_ind in range(1, len(attributes)):\n",
    "        attr_gain, attr_rich, attr_poor, attr_med = calc_gain(inp, attr_ind)\n",
    "        if(attr_gain>max_gn):\n",
    "            max_gn, max_ind, max_rich, max_poor, max_med = attr_gain, attr_ind, attr_rich, attr_poor, attr_med\n",
    "\n",
    "    return (-1*entropy + max_gn), max_ind, max_rich, max_poor, max_med\n",
    "\n",
    "def remove_node(ind, mq, iq, aq):\n",
    "    global dtree\n",
    "    ans = 1\n",
    "    dtree[iq[ind-1]][1][aq[ind-1]] = dtree[ind][2]\n",
    "    for i in range(len(dtree[ind][1])):\n",
    "        if(dtree[ind][1][i]>0):\n",
    "            ans += remove_node(dtree[ind][1][i], mq, iq, aq)\n",
    "    dtree[ind] = (dtree[ind][0], dtree[ind][1], dtree[ind][2], 0)\n",
    "    return ans\n",
    "\n",
    "def calc_prof(i, inp):\n",
    "    global dtree\n",
    "    if(dtree[i][3]==0):\n",
    "        return 0\n",
    "    if(dtree[i][2]==-1):\n",
    "        my_pred = 1\n",
    "    else:\n",
    "        my_pred = 0\n",
    "\n",
    "    new_corr = 0\n",
    "    old_corr = 0\n",
    "    for data_pt in inp:\n",
    "        if(data_pt[0]==my_pred):\n",
    "            new_corr += 1\n",
    "        if(data_pt[0]==predict(data_pt, i)):\n",
    "            old_corr += 1\n",
    "    return (new_corr - old_corr)\n",
    "\n",
    "def plot_node_acc(data_set, filename):\n",
    "    global dtree\n",
    "    fnl_dec = []\n",
    "    for data_pt in data_set:\n",
    "        temp_arr = []\n",
    "        ite = 1\n",
    "        while(ite<len(dtree)):\n",
    "            temp_arr.append((ite, dtree[ite][2]))\n",
    "            if(is_median(dtree[ite][0])):\n",
    "                temp_val = int(float(data_pt[dtree[ite][0]])>=dtree[ite][4])\n",
    "            else:\n",
    "                temp_val = data_pt[dtree[ite][0]]\n",
    "            if(dtree[ite][1][temp_val]==-1):\n",
    "                temp_arr.append((ite+1, -1))\n",
    "                break\n",
    "            elif(dtree[ite][1][temp_val]==-2):\n",
    "                temp_arr.append((ite+1, -2))\n",
    "                break\n",
    "            else:\n",
    "                ite = dtree[ite][1][temp_val]\n",
    "        fnl_arr = []\n",
    "        it = 0\n",
    "        for i in range(0, len(dtree)-1):\n",
    "            if(i<temp_arr[it][0]):\n",
    "                fnl_arr.append(temp_arr[it][1])\n",
    "            else:\n",
    "                it += 1\n",
    "                if(it==len(temp_arr)):\n",
    "                    it -= 1\n",
    "                fnl_arr.append(temp_arr[it][1])\n",
    "        corr_pred = []\n",
    "        for i in range(0, len(dtree) - 1):\n",
    "            if(data_pt[0] - fnl_arr[i]==2):\n",
    "                corr_pred.append(1)\n",
    "            else:\n",
    "                corr_pred.append(0)\n",
    "        fnl_dec.append(corr_pred)\n",
    "\n",
    "    fnl_dec = np.sum(fnl_dec, axis = 0)\n",
    "    fnl_dec = fnl_dec/len(data_set)\n",
    "    fnl_dec = fnl_dec*100\n",
    "    print(fnl_dec[-1])\n",
    "    plt.plot(fnl_dec)\n",
    "    plt.savefig(filename)\n",
    "    plt.close()\n",
    "\n",
    "def fnl_fnc(train_data, valid_data, test_data, prune):\n",
    "    global dtree\n",
    "    ite = 0\n",
    "    main_q = [train_data]\n",
    "#     valid_q = [valid_data]\n",
    "    ind_q = [0]\n",
    "    attr_q = [0]\n",
    "    curr_acc = 0\n",
    "    while(ite<len(main_q)):\n",
    "        inp = main_q[ite]\n",
    "        prev_ind = ind_q[ite]\n",
    "        attr_val = attr_q[ite]\n",
    "        gn, ind, rich, poor, med = max_gain(inp)\n",
    "        if(gn<=1e-15):\n",
    "            main_q = main_q[:ite] + main_q[(ite+1):]\n",
    "#             valid_q = valid_q[:ite] + valid_q[(ite+1):]\n",
    "            ind_q = ind_q[:ite] + ind_q[(ite+1):]\n",
    "            attr_q = attr_q[:ite] + attr_q[(ite+1):]\n",
    "            continue\n",
    "        my_ind = len(dtree)\n",
    "        temp_val = dtree[prev_ind][1][attr_val]\n",
    "        dtree[prev_ind][1][attr_val] = my_ind\n",
    "        temp_lst = []\n",
    "        for i in range(len(rich)):\n",
    "            if(rich[i]>poor[i]):\n",
    "                temp_lst.append(-1)\n",
    "            else:\n",
    "                temp_lst.append(-2)\n",
    "        dtree.append((ind, temp_lst, temp_val, 1, med))\n",
    "\n",
    "        new_inp = [[] for i in range(attr_len[ind])]\n",
    "        for data_pt in inp:\n",
    "            if(is_median(ind)):\n",
    "                temp_val = int(float(data_pt[ind])>=med)\n",
    "            else:\n",
    "                temp_val = data_pt[ind]\n",
    "            new_inp[temp_val].append(data_pt)\n",
    "\n",
    "#         valid_inp = [[] for i in range(attr_len[ind])]\n",
    "#         for data_pt in valid_q[ite]:\n",
    "#             valid_inp[data_pt[ind]].append(data_pt)\n",
    "\n",
    "        for i in range(attr_len[ind]):\n",
    "            main_q.append(new_inp[i])\n",
    "#             valid_q.append(valid_inp[i])\n",
    "            ind_q.append(my_ind)\n",
    "            attr_q.append(i)\n",
    "\n",
    "        ite += 1\n",
    "\n",
    "#     if(prune):\n",
    "#         X = []\n",
    "#         Y = []\n",
    "#         num_nodes = len(dtree)-1\n",
    "#         max_nodes = num_nodes\n",
    "#         while(True):\n",
    "#             max_prof = float('-inf')\n",
    "#             max_ind = -1\n",
    "#             for i in range(1, len(dtree)):\n",
    "#                 this_prof = calc_prof(i, valid_q[i-1])\n",
    "#                 if(this_prof>0 and this_prof>max_prof):\n",
    "#                     max_prof = this_prof\n",
    "#                     max_ind = i\n",
    "#             if(max_ind==-1):\n",
    "#                 break\n",
    "#             print(max_prof)\n",
    "#             X.append(num_nodes)\n",
    "#             Y.append(get_acc(valid_data))\n",
    "#             rem_node = remove_node(max_ind, valid_q, ind_q, attr_q)\n",
    "#             num_nodes = num_nodes - rem_node\n",
    "# #             print(X, Y)\n",
    "#         X.append(num_nodes)\n",
    "#         Y.append(get_acc(valid_data))\n",
    "#         print(get_acc(valid_data))\n",
    "#         plt.plot(X, Y)\n",
    "#         plt.xlim(max_nodes+100, num_nodes-100)\n",
    "#         plt.savefig(\"test_prune.png\")\n",
    "#         plt.close()\n",
    "#         print(num_nodes)\n",
    "\n",
    "\n",
    "\n",
    "#     plot_node_acc(valid_data, \"valid_data.png\")\n",
    "#     print(\"valid done\")\n",
    "#     plot_node_acc(test_data, \"test_data.png\")\n",
    "#     print(\"test done\")\n",
    "#     plot_node_acc(train_data, \"train_data.png\")\n",
    "#     print(\"train done\")\n",
    "\n",
    "\n",
    "    plot_node_acc(valid_data, \"valid_data_med.png\")\n",
    "    print(\"valid done\")\n",
    "    plot_node_acc(test_data, \"test_data_med.png\")\n",
    "    print(\"test done\")\n",
    "    plot_node_acc(train_data, \"train_data_med.png\")\n",
    "    print(\"train done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80.43333333333334\n",
      "valid done\n",
      "79.92857142857143\n",
      "test done\n",
      "92.58518518518518\n",
      "train done\n"
     ]
    }
   ],
   "source": [
    "rich = 0\n",
    "poor = 0\n",
    "for data_pt in train_data:\n",
    "    if(data_pt[0]==0):\n",
    "        poor += 1\n",
    "    else:\n",
    "        rich += 1\n",
    "dtree = []\n",
    "if (rich>poor):\n",
    "    dtree.append((-1, [-1], -1, 0))\n",
    "else:\n",
    "    dtree.append((-1, [-2], -2, 0))\n",
    "fnl_fnc(train_data, valid_data, test_data, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "40\n",
      "50.0\n",
      "55\n",
      "60\n"
     ]
    }
   ],
   "source": [
    "def traversal(dtree_ind, my_ind):\n",
    "    global dtree\n",
    "    attr_ind = dtree[dtree_ind][0]\n",
    "    max_lst = []\n",
    "    max_height = 0\n",
    "    for i in range(len(dtree[dtree_ind][1])):\n",
    "        if(dtree[dtree_ind][1][i]>0):\n",
    "            temp_lst, height = traversal(dtree[dtree_ind][1][i], my_ind)\n",
    "            if(height>max_height):\n",
    "                max_lst, max_height = temp_lst, height\n",
    "    if(attr_ind==my_ind):\n",
    "        max_lst.append(dtree_ind)\n",
    "    return max_lst, len(max_lst)\n",
    "\n",
    "fnl_lst, leng = traversal(1, 13)\n",
    "print(leng)\n",
    "if(leng>1):\n",
    "    for ele in reversed(fnl_lst):\n",
    "        print(dtree[ele][4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 1]\n"
     ]
    }
   ],
   "source": [
    "def arr(c):\n",
    "    a = c\n",
    "    a.append(1)\n",
    "    return a\n",
    "\n",
    "a = [1, 2, 3]\n",
    "b = arr(a)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0],\n",
       "       [0, 2]])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [1, 2]\n",
    "np.diag(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8652222222222222\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "clf = tree.DecisionTreeClassifier(min_samples_split=200, min_samples_leaf=1, max_depth=20)\n",
    "X = []\n",
    "Y = []\n",
    "for data_pt in train_data:\n",
    "    Y.append(data_pt[0])\n",
    "    X.append(data_pt[1:])\n",
    "clf = clf.fit(X, Y)\n",
    "X = []\n",
    "Y = []\n",
    "for data_pt in train_data:\n",
    "    Y.append(data_pt[0])\n",
    "    X.append(data_pt[1:])\n",
    "arr = clf.predict(X)\n",
    "\n",
    "count = 0\n",
    "total = 0\n",
    "for ele, ele2 in zip(arr, Y):\n",
    "    if(ele==ele2):\n",
    "        count += 1\n",
    "    total += 1\n",
    "print((count+0.0)/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9999629629629629\n"
     ]
    }
   ],
   "source": [
    "from sklearn import ensemble\n",
    "clf = ensemble.RandomForestClassifier(n_estimators = 100, max_features = 4, bootstrap=True)\n",
    "X = []\n",
    "Y = []\n",
    "for data_pt in train_data:\n",
    "    Y.append(data_pt[0])\n",
    "    X.append(data_pt[1:])\n",
    "clf = clf.fit(X, Y)\n",
    "\n",
    "X = []\n",
    "Y = []\n",
    "for data_pt in train_data:\n",
    "    Y.append(data_pt[0])\n",
    "    X.append(data_pt[1:])\n",
    "arr = clf.predict(X)\n",
    "\n",
    "count = 0\n",
    "total = 0\n",
    "for ele, ele2 in zip(arr, Y):\n",
    "    if(ele==ele2):\n",
    "        count += 1\n",
    "    total += 1\n",
    "\n",
    "print((count+0.0)/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
